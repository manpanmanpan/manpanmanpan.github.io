---
layout:     post
title:      Hive
subtitle:   
date:       2019-4-21
author:     Cassie Pan
header-img: img/post-bg-rwd.jpg 
catalog: true
tags:
    -  
---


### This is a note for the diffference between SQL and Hive

- Mapreduce  ------- SQL ------ > Hive
- Spark ------- SQL ------- > Spark SQL

### 1. Create Table  &  Load

```
CREATE TABLE order (id INT, name STRING, capacity STRING, price DOUBLE)
    COMMENT 'This is the order table'
    ROW FORMAT DELIMITED
        FIELDS TERMINATED BY '\t'
STORES AS SEQUENCEFILE;

Load data local inpath 'home/hadoop/xxx.txt' into table order;
```

### 2. External tabel (connect to external data) VS Managed table (connect to local data)

```
CREATE EXTERNAL TABLE order_external (id INT, name STRING, capacity STRING, price DOUBLE)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY '\t'
    LOCATION '/external/hive_ext';

```

Note: 
For internal (Managed) table, drop table order, we will drop all data and file;
for external table, drop table order_external, we will just drop data, the file is still in the hadoop dictionary path.

### 3. CTAS (Create a new temporary table)

```
CREATE TABLE Order_new
AS
SELECT id, name, price from order;
```

### 4. Insert (insert data to a exsiting temporary table)

- Hive doesn't support insert a row data, but can import a dataset.

```
Insert overwrite table order_new2
    SELECT * FROM order;
```

### 5. Partition

```
CREATE TABLE order_pati (id INT, name STRING, capacity STRING, price DOUBLE)
    PARTITIONED BY (month STRING)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY '\t';
    
```

```
Load data local inpath '/home/hadoop/xxx.data' into table order_pati partition ( month = '201901');
Load data local inpath '/home/hadoop/yyy.data' into table order_pati partition ( month = '201902');

```

That code will create a new file named 'month = 201901' under order_pati file, which has xxx.data.
Then:

```
SELECT COUNT(*) FROM order_pati WHERE MONTH = '201901';
SELECT * FROM order_pati WHERE MONTH = '201901';


Show partitions order_pati;
```

### 6. Array

```
CREATE TABLE TAB_ARRAY (A ARRAY<INT>), B ARRAY<STRING>)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY '\t'  # using '\t' to split A and B 
    collection items terminated by ','; # using ',' to split items inside array 

```
For example, the data should be like : 
    123,212,125  a,v,b
    232,434,675  b,f,t
    344,678,908  n,m,k


### 7. Map (key: value; key: value)

```
Create table tab_map (name string, info map<string, string>)
    ROW FORMAT DELIMITED
    FIELDS TERMINATED BY '\t'  
    collection items terminated by ';'
    map keys terminated by ':';

```

For Example, the data should be like:
    furong   age:28; height:167; addr: Beijing
    wangqin  age:22; height:178; addr: USA; Weight:132 (map length can be different)

### 8. cli shell (利用脚本语言（bash shell, python）进行hql语句的批量执行)

```
hive -S -e 'select country count(*) from tab_ext' > /home/hadoop/hivetemp/e.txt

```

### 9. UDF
```
hive>add jar /home/hadoop/myudf.jar;
hive>CREATE TEMPORARY FUNCTION my_lower AS 'org.dht.Lower'; # connect to java class ('org.dht.Lower')
select my_lower(name) from tab_ext;
```

过程： 

- 写一个JAVA类， 定义自定义的函数逻辑
- 打成Jar包
- 上传到hive的lib中
- 在hive中创一个函数， 跟jar包中的自定义java类建立联系